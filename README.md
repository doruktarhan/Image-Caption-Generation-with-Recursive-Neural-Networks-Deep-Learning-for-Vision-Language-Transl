# Image-Caption-Generation-with-Recursive-Neural-Networks-Deep-Learning-for-Vision-Language-Translation Models


This project is about image captioning task using deep learning architectures and techniques. In the aspect of my work, the main objective of the process is that designing an architecture that gives a textual description of the given input image. The task will be done by the help of both natural language processing and the computer vision architectures. 

The computer vision part of the project will contain Convolutional Neural Network to encode images and it will be followed by the NLP part which contains Recurrent Neural Network to decode the encoded images and vocabulary to make reasonable captions for the images. The RNN model is made up of LSTM (Long Short Term Memory) units and it will follow the teacher force algorithm which is an algorithm generally used in these type of applications. 

In the CNN part of the project, transfer learning applications such as ResNet, VGGNet, Inception_V3 will be used rather than training a CNN unit from scratch.  Flickr dataset will be used for training and test. The model is optimized with Dropout and Adam optimizer.


Detailed information is given in the results pdf. 
